# -*- coding: utf-8 -*-
"""Netflix Case Study.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VRFyZHJGvM34PFMYeQZoocfj70CPQw16
"""

# importing libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Downloading Dataset
!gdown 1UhnJHhqp0L89TQr2zayZ-rpDR6fFGns5

df  = pd.read_csv('/content/netflix_titles.csv')

df.head()

df.tail()

df.info()

df.shape

df.columns

# number of unique values in our data
for i in df.columns:
  print(i,':',df[i].nunique())

df.nunique()

# checking null values in every column of our  data
df.isnull().sum()

# checking the % of null values in every column of our  data
df.isnull().sum()/len(df)*100

"""Note: director column has 29% null values"""

# checking the occurences of each of the rating
df['rating'].value_counts()

"""Note: 74 min, 84 min, 66 min are outlier in rating column

--------------------------------
# Data Preprocessing

## Challenges
1. Nested data
2. Missing Values
3. Missing continuous variables
4. Incorrect data type assigned
"""

# unnesting the director column, i.e- creating separate line for each director in a movie
constraint1 = df['director'].apply(lambda x : str(x).split(', ')).tolist()
df_new1 = pd.DataFrame(constraint1, index=df['title'])
df_new1 = pd.DataFrame(df_new1.stack())
df_new1 = pd.DataFrame(df_new1.reset_index())
df_new1.drop(['level_1'], axis=1, inplace=True)
df_new1.rename(columns={0:'Directors'}, inplace=True)
df_new1.head()

# unnesting the cast column, i.e- creating separate line for each cast member in a movie
constraint2 = df['cast'].apply(lambda x:str(x).split(', ')).tolist()
df_new2 = pd.DataFrame(constraint2, index=df['title'])
df_new2 = pd.DataFrame(df_new2.stack())
df_new2 = pd.DataFrame(df_new2.reset_index())
df_new2.drop(['level_1'], axis=1, inplace=True)
df_new2.rename(columns={0:'Actors'}, inplace=True)
df_new2.head()

# unnesting the listed_in column, i.e- creating separate line for each genre member in a movie
constraint3 = df['listed_in'].apply(lambda x:str(x).split(', ')).tolist()
df_new3 = pd.DataFrame(constraint3, index=df['title'])
df_new3 = pd.DataFrame(df_new3.stack().reset_index())
df_new3.drop(['level_1'], axis=1, inplace=True)
df_new3.rename(columns={0:'Genre'}, inplace=True)
df_new3.head()

# unnesting the country column, i.e- creating separate line for each country member in a movie
constraint4 = df['country'].apply(lambda x: str(x).split(', ')).tolist()
df_new4 = pd.DataFrame(constraint4, index=df['title'])
df_new4 = pd.DataFrame(df_new4.stack().reset_index())
df_new4.drop(['level_1'], axis=1, inplace=True)
df_new4.rename(columns={0:'country'}, inplace=True)
df_new4.head()

# Merging the unnested director data with unnested actors data
df_new5 = df_new2.merge(df_new1, on=['title'], how='inner')

# Merging the above merge data  with unnested genre data
df_new6 = df_new5.merge(df_new3, on=['title'], how='inner')

# Merging the above merge data  with unnested country data
df_new = df_new6.merge(df_new4, on=['title'], how='inner')

# Replacing nan values of director and actor by Unknown Actor and Director
df_new['Actors'].replace(['nan'],['Unknown Actor'], inplace=True)
df_new['Directors'].replace(['nan'],['Unknown Director'], inplace=True)
df_new['country'].replace(['nan'],[np.nan], inplace=True)
df_new.head()

df_new.shape

df.columns

# Merging our unnested data with original data
df_final = df_new.merge(df[['show_id', 'type', 'title', 'date_added','release_year', 'rating', 'duration']], on=['title'], how='left')
df_final.head()

# now checking nulls
df_final.isnull().sum()

"""In duration column, it was observed that the nulls had values which were written in corresponding ratings column, i.e you can't expact the duration column nulls are replaced by corresponding values in ratings column"""

df_final.loc[df_final['duration'].isnull(), 'duration'] = df_final.loc[df_final['duration'].isnull(),'duration'].fillna(df_final['rating'])

# Rating can't be in min, so it has made NR(i.e- Non Rated)
df_final.loc[df_final['rating'].str.contains('min',na=False),'rating'] = 'NR'

df_final.isnull().sum()

# Rating can't be in min, so it has made NR(i.e- Non Rated)
df_final.loc[df_final['rating'].str.contains('min', na=False),'rating']='NR'
df_final['rating'].fillna('NR', inplace=True)
pd.set_option('display.max_row',None)

# just an attempt to observe null values in date_added column
df_final[df_final['date_added'].isnull()].head()

df_final.head()

df_final['duration'].value_counts().head()

# Removing min from data
df_final['duration'] = df_final['duration'].str.replace(" min","")
df_final.head()

df_final['duration'] = df_final['duration'].str.replace(" Seasons","")
df_final['duration'] = df_final['duration'].str.replace(" Season","")

df_final.head()

df_final['duration'].unique()

sns.distplot(df_final['duration'], hist=True, kde=True, bins=int(36),color='darkblue',hist_kws={'edgecolor':'black'}, kde_kws={'linewidth':4})
plt.show()

"""The Average duration for movies are 90 min"""

sns.countplot(df['type']) 
plt.show()

# from datetime import datetime
# from dateutil.parser import parse
# arr=[]
# for i in df_final['date_added'].values:
#   dt1=parse(i)
#   arr.append(dt1.strftime('%Y-%m-%d'))
# df_final['Modified_Added_date']=arr
# df_final['Modified_Added_date']=pd.to_datetime(df_final['Modified_Added_date'])
# df_final['month_added']=df_final['Modified_Added_date'].dt.month
# df_final['week_added']=df_final['Modified_Added_date'].dt.week
# df_final['year']=df_final['Modified_Added_date'].dt.year
# df_final.head()



# number of distinct titles on the basis of genre
df_final.groupby(['Genre']).agg({'title':'nunique'}).sort_values(by=['title'], ascending=False)

"""**Observation** : The most popular Genre across the countries and in both TV Shows and Movies are Drama, Comedy and International TV Shows/Movies, so content aligning to that is recommended."""

